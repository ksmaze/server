name: Build and Push Triton CPU Image

on:
  workflow_dispatch:
    inputs:
      backend_type:
        description: 'Backend type to build'
        required: true
        type: choice
        options:
          - generic
          - tensorflow
        default: 'generic'
      version_tag:
        description: 'Version tag (e.g., 25.11)'
        required: true
        default: '25.11'

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ksmaze/triton_cpu

jobs:
  build-and-push:
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      packages: write

    steps:
      - name: Free disk space
        uses: jlumbroso/free-disk-space@main
        with:
          tool-cache: false
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          docker-images: true
          swap-storage: true

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install distro requests

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set image tag
        id: tag
        run: |
          if [ "${{ inputs.backend_type }}" == "tensorflow" ]; then
            echo "tag=${{ inputs.version_tag }}-tf2" >> $GITHUB_OUTPUT
          else
            echo "tag=${{ inputs.version_tag }}" >> $GITHUB_OUTPUT
          fi

      - name: Build Triton (generic)
        if: inputs.backend_type == 'generic'
        run: |
          python build.py \
            --no-container-interactive \
            --enable-metrics \
            --enable-logging \
            --enable-stats \
            --enable-cpu-metric \
            --backend ensemble \
            --backend onnxruntime \
            --backend openvino \
            --backend python \
            --endpoint=grpc \
            --endpoint=http

      - name: Build Triton (tensorflow)
        if: inputs.backend_type == 'tensorflow'
        run: |
          python build.py \
            --no-container-interactive \
            --enable-metrics \
            --enable-logging \
            --enable-stats \
            --enable-cpu-metric \
            --backend ensemble \
            --backend tensorflow \
            --endpoint=grpc \
            --endpoint=http

      - name: Tag and push image
        run: |
          docker tag tritonserver:latest ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.tag.outputs.tag }}
          docker push ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.tag.outputs.tag }}
          echo "Pushed: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.tag.outputs.tag }}"
